{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69608d-8ec5-422a-81b5-6434cb29b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b363cbd-def0-425a-8858-36aa35c2324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1377ec-d79d-47ba-b40c-3bc31de18410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model path to save in the same directory as this script\n",
    "MODEL_PATH = os.getenv(\"MODEL_PATH\", \"bank_model.pkl\")\n",
    "DATA_URL = os.getenv(\"DATA_URL\", \"./bank.csv\")  # Path to your CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9066a-96b1-4b40-98e9-adc239d24102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Load the trained model from a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(MODEL_PATH, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        logging.info(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error loading model: %s\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaca5af-48bf-4786-9aef-9c68a44c1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(url):\n",
    "    \"\"\"Load dataset from a given URL.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {url}\")\n",
    "        \n",
    "        # Check if the file exists and log its size\n",
    "        if not os.path.exists(url):\n",
    "            logging.error(\"Data file does not exist.\")\n",
    "            return None\n",
    "        \n",
    "        file_size = os.path.getsize(url)\n",
    "        logging.info(f\"File size: {file_size} bytes\")\n",
    "\n",
    "        data = pd.read_csv(url, sep=',')  # Use comma as the separator\n",
    "        if data.empty:\n",
    "            logging.error(\"Loaded data is empty.\")\n",
    "            return None\n",
    "        \n",
    "        logging.info(\"Data loaded successfully.\")\n",
    "        logging.info(f\"Columns in loaded data: {data.columns.tolist()}\")  # Log the columns\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error loading data: %s\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f6a15-9633-4707-bf61-778737370cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the data (if needed).\"\"\"\n",
    "    # Save the target variable\n",
    "    target = data['y']\n",
    "    \n",
    "    # Convert categorical variables to dummy variables, dropping the target\n",
    "    data = pd.get_dummies(data.drop('y', axis=1), drop_first=True)\n",
    "    \n",
    "    # Add the target variable back\n",
    "    data['y'] = target\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533c990-fde3-4bb0-bc22-e1ea0db75acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data):\n",
    "    \"\"\"Train a machine learning model.\"\"\"\n",
    "    if 'y' not in data.columns:\n",
    "        raise ValueError(\"Target column 'y' not found in the dataset.\")\n",
    "\n",
    "    X = data.drop('y', axis=1)  # Features\n",
    "    y = data['y']                # Target variable\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    logging.info(f\"Model accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83052695-3bc2-46b7-a321-961a31fdabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \"\"\"Save the trained model as a pickle file.\"\"\"\n",
    "    with open(MODEL_PATH, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    logging.info(f\"Model saved as {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e08be-cf30-40a9-9e9f-0cda241c66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    \"\"\"Home route.\"\"\"\n",
    "    return jsonify({\"message\": \"Welcome to the Bank Model API. Use /train to train the model and /predict to make predictions.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addaea3-f475-442a-af87-0f748052d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"Predict endpoint.\"\"\"\n",
    "    data = request.json\n",
    "    if not data:\n",
    "        return jsonify({\"error\": \"No data provided\"}), 400\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    try:\n",
    "        df = preprocess_data(df)\n",
    "        model = load_model()\n",
    "        predictions = model.predict(df)\n",
    "        return jsonify(predictions.tolist())\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6c195-75ca-4714-85ab-effdf4d2eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/train', methods=['POST'])\n",
    "def train():\n",
    "    \"\"\"Train endpoint.\"\"\"\n",
    "    data = load_data(DATA_URL)\n",
    "    \n",
    "    if data is not None:\n",
    "        processed_data = preprocess_data(data)\n",
    "        model = train_model(processed_data)\n",
    "        save_model(model)\n",
    "        return jsonify({\"message\": \"Model trained and saved.\"})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Data loading failed.\"}), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e7f60-db62-4bef-aba4-68887498ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Train the model when the script is run\n",
    "    data = load_data(DATA_URL)\n",
    "    if data is not None:\n",
    "        processed_data = preprocess_data(data)\n",
    "        model = train_model(processed_data)\n",
    "        save_model(model)\n",
    "    else:\n",
    "        logging.error(\"Initial data loading failed.\")\n",
    "\n",
    "    # Run the Flask app\n",
    "    app.run(host='0.0.0.0', port=5087)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
